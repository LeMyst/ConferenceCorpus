#!/bin/bash
# WF 2020-08-21
# Crawl WikiCFP and save to JSON
python3 --version
export PYTHONPATH="."
target=$HOME/.conferencecorpus/wikicfp/crawl
if [ ! -d $target ]
then
   mkdir -p $target
fi
# loop over page batches of 1000
for base in {0..140..1}
do
  startId=$((base*1000))
  stopId=$((base*1000+999))
  jsonFileName=$(printf "wikicfp_Event%06d-%06d.json" $startId $stopId)
  jsonFile="$target/$jsonFileName"
  if [ -f "$jsonFile" ]
  then
    echo "$jsonFileName ✅"
    if [ $base -ge 140 ]
    then
      jq . $jsonFile
    fi
    else
      echo "$jsonFileName ❌"
      # immediately fetch the batch with one thread
      python3 datasources/wikicfpscrape.py --startId ${startId} --stopId ${stopId} -t 1 --targetPath $target
    fi
done
# fetch multithreaded
# be polite and do not do this ...
# python3 datasources/wikicfpscrape.py --startId ${base}0000 --stopId ${base}9999 -t 10 --targetPath $target
